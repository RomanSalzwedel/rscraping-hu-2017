sapply(mtcars, is.numeric)
foo <- sapply(mtcars, is.numeric)
class(foo)
sapply(mtcars, is.numeric) %>% class
a <- matrix(1:20, nrow = 5)
a
apply(a, 1, mean)
apply(a, 2, mean)
apply(mtcars, 2, mean)
apply(mtcars, 1, mean)
names(mtcars)
apply(mtcars[,1:2], 1, mean)
mtcars[,1:2] %>% apply(1, mean)
apply(mtcars[,1:2], 1, mean)
names(mtcars)
apply(mtcars[,c("gear", "carb")], 1, mean)
select(mtcars, gear, carb)
select(mtcars, gear, carb) %>% apply(1, mean)
?runif
?rnorm
runif(10)
runif(10)
runif(10)
runif(10)
runif(10)
runif(10)
xs <- replicate(5, runif(10), simplify = FALSE)
xs
ws <- replicate(5, rpois(10, 5) + 1, simplify = FALSE)
ws
?weighted.mean
Map(weighted.mean, xs, ws)
Map(weighted.mean, xs, ws) %>% unlist
mtcars
mtcars$mpg
mtcars$mpg %>% class
(current_folder <- getwd())
setwd("/Users/munzerts/github/")
setwd("/Users/munzerts/github/rscraping-hu-2017")
dir.create("data")
dir.create("data/r-data")
# get all pre-compiled data sets
dat <- as.data.frame(data(package = "datasets")$results)
dat$Item %<>% str_replace(" \\(.+\\)", "")
dat
# store data sets in local folder
for (i in 1:50) {
try(df_out <- dat$Item[i] %>% as.character %>% get)
save(df_out, file = paste0("data/r-data/", dat$Item[i], ".RData"))
}
dir()
dir("data/r-data")
filenames <- dir("data/r-data", full.names = TRUE)
filenames
dir("data/r-data", pattern = "US")
dir("data/r-data", pattern = "US", ignore.case = TRUE)
?files
filenames
basename(filenames)
url <- "http://www.mzes.uni-mannheim.de/d7/en/news/media-coverage/ist-die-wahlforschung-in-der-krise-der-undurchschaubare-buerger"
url
basename(url)
dirname(url)
file_inf <- file.info(dir(recursive = F))
file_inf
tools::file_ext(filenames)
filenames
tools::file_ext(dir())
file.exists(filenames)
file.exists("voterfile.RData")
file.exists(filenames)
file.exists()
(foo <- file.choose())
source("packages.r")
library(stringr)
string1 <- "This is a string"
string1 %>% class()
double_quote <- "\"" # or '"'
double_quote
?"'"
double_quote
writeLines(double_quote) # shows raw contents of the string
cat(double_quote)
x <- "\u00b5"
x
writeLines(x)
x
double_quote
x <- c("apple", "banana", "pear")
x
?str_view
str_view(x, "an")
str_view_all(x, "an")
str_view_all(x, "a")
raw.data <- "555-1239Moe Szyslak(636) 555-0113Burns, C. Montgomery555-6542Rev. Timothy Lovejoy555 8904Ned Flanders636-555-3226Simpson, Homer5553642Dr. Julius Hibbert"
raw.data
name <- unlist(str_extract_all(raw.data, "[[:alpha:]., ]{2,}"))
name
phone <- unlist(str_extract_all(raw.data, "\\(?(\\d{3})?\\)?(-| )?\\d{3}(-| )?\\d{4}"))
phone
str_extract_all(raw.data, "[[:alpha:]., ]{2,}")
name <- unlist(str_extract_all(raw.data, "[[:alpha:]., ]{2,}"))
name
example.obj <- "1. A small sentence. - 2. Another tiny sentence."
example.obj
str_extract(example.obj, "small")
str_extract(example.obj, "banana")
(out <- str_extract_all(c("text", "manipulation", "basics"), "a"))
c("text", "manipulation", "basics"), "a"
c("text", "manipulation", "basics")
(out <- str_extract_all(c("text", "manipulation", "basics"), "a"))
str_extract(example.obj, "small")
str_extract(example.obj, "SMALL")
str_extract(example.obj, ignore.case("SMALL")) # wrong
str_extract(example.obj, regex("SMALL", ignore_case = TRUE))
example.obj
str_extract(example.obj, "mall sent")
str_extract(example.obj, "^1")
str_extract(example.obj, "^2")
str_extract(example.obj, "sentence$")
str_extract(example.obj, "sentence.$")
unlist(str_extract_all(example.obj, "tiny|sentence"))
str_extract(example.obj, "sm.ll")
str_extract(example.obj, "sm[abc]ll")
str_extract(example.obj, "sm[a-p]ll")
unlist(str_extract_all(example.obj, "[uvw. ]"))
example.obj
unlist(str_extract_all(example.obj, "[:punct:]"))
?base::regex
unlist(str_extract_all(example.obj, "[[:punct:]ABC]"))
unlist(str_extract_all(example.obj, "[^[:alnum:]]"))
str_extract(example.obj, "s[[:alpha:]][[:alpha:]][[:alpha:]]l")
str_extract(example.obj, "s[[:alpha:]]{3}l")
str_extract(example.obj, "A.+sentence")
str_extract(example.obj, "A.+?sentence")
unlist(str_extract_all(example.obj, "(.en){1,5}"))
unlist(str_extract_all(example.obj, ".en{1,5}"))
unlist(str_extract_all(example.obj, "(.en){1,4}"))
unlist(str_extract_all(example.obj, "(.en){1,3}"))
unlist(str_extract_all(example.obj, "(.en)"))
unlist(str_extract_all(example.obj, "(.en){1,1}"))
unlist(str_extract_all(example.obj, "(.en){1,5}"))
unlist(str_extract_all(example.obj, "(.en){2,5}"))
unlist(str_extract_all(example.obj, "(.en){1,5}"))
unlist(str_extract_all(example.obj, "(.en){1,6}"))
unlist(str_extract_all(example.obj, "(.en){1,7}"))
unlist(str_extract_all(example.obj, "(.en){1,3}"))
example.obj
unlist(str_extract_all(example.obj, "\\."))
unlist(str_extract_all(example.obj, fixed(".")))
unlist(str_extract_all(example.obj, fixed("sentence.")))
unlist(str_extract_all(example.obj, "[12-]"))
unlist(str_extract_all(example.obj, "[1-2]"))
example.obj
str_extract(example.obj, "([[:alpha:]]).+?\\1")
str_extract(example.obj, "(\\b[a-z]+\\b).+?\\1")
unlist(str_extract_all(example.obj, "(?<=2. ).+")) # positive lookbehind: (?<=...)
unlist(str_extract_all(example.obj, ".+(?=2)")) # positive lookahead (?=...)
unlist(str_extract_all(example.obj, "(?<!Blah )tiny.+")) # negative lookbehind: (?<!...)
unlist(str_extract_all(example.obj, "sentence.+(?!Bla)")) # negative lookahead (?!...)
browseURL("http://stackoverflow.com/questions/201323/using-a-regular-expression-to-validate-an-email-address/201378#201378") # think again
source("packages.r")
source("functions.r")
example.obj <- "1. A small sentence. - 2. Another tiny sentence."
example.obj
str_locate(example.obj, "tiny")
str_sub(example.obj, start = 35, end = 38)
str_sub(example.obj, 35, 38) <- "huge"
str_sub(example.obj, 35, 38) <- "huge"
example.obj
str_replace(example.obj, pattern = "huge", replacement = "giant")
str_split(example.obj, "-")
str_split(example.obj, "-") %>% unlist
str_split_fixed(example.obj, "[[:blank:]]", 5) %>% as.character()
(char.vec <- c("this", "and this", "and that"))
char.vec
str_detect(char.vec, "this")
str_subset(char.vec, "this") # wrapper around x[str_detect(x, pattern)]
str_count(char.vec, "this")
str_count(char.vec, "\\w+")
str_length(char.vec)
str_dup(char.vec, 3)
length.char.vec <- str_length(char.vec)
char.vec
length.char.vec <- str_length(char.vec)
length.char.vec
char.vec <- str_pad(char.vec, width = max(length.char.vec), side = "both", pad = " ")
char.vec
str_trim(char.vec)
?str_trim
str_c("text", "manipulation", sep = " ")
str_c("text", "manipulation", sep = " ")
str_c(char.vec, collapse = "\n") %>% cat
str_c(char.vec, collapse = "\n")
str_c(char.vec, collapse = "\n") %>% cat
str_c("text", c("manipulation", "basics"), sep = " ")
agrep("Donald Trump", "Donald Drumpf", max.distance = list(all = 3))
?agrep
agrepl("Donald Trump", "Donald Drumpf", max.distance = list(all = 3))
agrep("Donald Trump", "Barack Obama", max.distance = list(all = 3))
agrepl("Donald Trump", "Barack Obama", max.distance = list(all = 3))
library(stringi)
example.obj
stri_count_words(example.obj)
stri_stats_latex(example.obj)
stri_stats_general(example.obj)
stri_escape_unicode("\u00b5")
stri_unescape_unicode("\u00b5")
stri_rand_lipsum(3)
stri_rand_shuffle("hello")
stri_rand_strings(100, 10, pattern = "[humboldt]")
browseURL("https://www.nytimes.com/")
browseURL("http://flukeout.github.io/") # let's play this together until plate 8 or so!
source("packages.r")
email <- "chunkylover53[at]aol[dot]com"
email_new <- email %>% str_replace("\\[at\\]", "@") %>% str_replace("\\[dot\\]", ".")
email_new
str_extract(email_new, "[:digit:]+")
regex <- ".*"
string <- c("1. This is an example string by", "2. Eddie (born 1961 in München)", "!§%$&/)(}")
str_extract_all(string, regex)
raw.data <- "555-1239Moe Szyslak(636) 555-0113Burns, C. Montgomery555-6542Rev. Timothy Lovejoy555 8904Ned Flanders636-555-3226Simpson, Homer5553642Dr. Julius Hibbert"
(name <- unlist(str_extract_all(raw.data, "[[:alpha:]., ]{2,}")))
(name_sorted <-  str_replace(name, "(.+), (.+)", "\\2 \\1"))
has_title <- str_detect(name, pattern="Dr\\. |Rev\\.")
has_title
name_elements <- str_count(name_sorted, "\\w+")
has_second_name <- ifelse(has_title == FALSE & name_elements > 2, TRUE,
ifelse(has_title == TRUE & name_elements > 3, TRUE, FALSE))
has_second_name
string <- "<title>+++BREAKING NEWS+++</title>"
str_extract(string, "<.+>")
str_extract(string, "<.+?>")
string <- "(5-3)^2=5^2-2*5*3+3^2 conforms to the binomial theorem"
regex <- "[^0-9=+*()]+"
str_extract_all(string, regex)
regex_correct <- "[[:digit:][:punct:]]+"
regex_correct_alt <- "[[:digit:]()=*-^]+"
regex_correct
str_extract_all(string, regex_correct)
str_extract_all(string, regex_correct_alt)
secret <- "clcopCow1zmstc0d87wnkig7OvdicpNuggvhryn92Gjuwczi8hqrfpRxs5Aj5dwpn0TanwoUwisdij7Lj8kpf03AT5Idr3coc0bt7yczjatOaootj55t3Nj3ne6c4Sfek.r1w1YwwojigOd6vrfUrbz2.2bkAnbhzgv4R9i05zEcrop.wAgnb.SqoU65fPa1otfb7wEm24k6t3sR9zqe5fy89n6Nd5t9kc4fE905gmc4Rgxo5nhDk!gr"
(solved <- unlist(str_extract_all(secret, "[[:upper:][:punct:]]")))
str_c(solved, collapse="")
browseURL("https://www.jstatsoft.org/about/editorialTeam")
browseURL("http://www.whoishostingthis.com/tools/user-agent/")
uastring <- "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36"
session <- html_session("http://www.google.com", user_agent(uastring))
search <- html_form(session)[[1]]
library(rvest)
url <- "http://en.wikipedia.org/wiki/List_of_MPs_elected_in_the_United_Kingdom_general_election,_1992"
url_parsed <- read_html(url)
tables <- html_table(url_parsed, fill = TRUE)
names(tables)
mps <- tables[[4]]
head(mps)
# clean up
head(mps)
names(mps) <- c("con", "name", "party")
mps <- mps[-1,]
mps <- mps[!is.na(as.character(mps$party)),]
nrow(mps)
# look for Sirs
mps$name <- as.character(mps$name)
mps$sir <- str_detect(mps$name, "^Sir ")
table(mps$party, mps$sir)
prop.table(table(mps$party, mps$sir), 1)
library(stringr)
mps$name <- as.character(mps$name)
mps$sir <- str_detect(mps$name, "^Sir ")
table(mps$party, mps$sir)
mps <- tables[[4]]
head(mps)
head(mps)
names(mps) <- c("con", "name", "party")
mps <- mps[-1,]
tables <- html_table(url_parsed, fill = FALSE)
tables <- html_table(url_parsed, fill = TRUE)
names(tables)
mps <- tables[[4]]
head(mps)
mps <- filter(mps, !str_detect("[edit"))
mps <- filter(mps, !str_detect(X2, "[edit"))
mps <- mps[!str_detect(mps$X1, "[edit"),]
mps <- mps[!str_detect(mps$X1, "\\[edit"),]
nrow(mps)
# look for Sirs
mps$name <- as.character(mps$name)
mps$sir <- str_detect(mps$name, "^Sir ")
table(mps$party, mps$sir)
prop.table(table(mps$party, mps$sir), 1)
mps$name <- as.character(mps$name)
head(mps)
tables <- html_table(url_parsed, fill = TRUE)
names(tables)
mps <- tables[[4]]
head(mps)
head(mps)
names(mps) <- c("con", "name", "party")
mps <- mps[!str_detect(mps$X1, "\\[edit"),]
mps <- mps[-1,]
nrow(mps)
str_detect(mps$X1, "\\[edit")
str_detect(mps$X1, "\\[edit")
head(mps)
names(mps) <- c("con", "name", "party")
url_parsed <- read_html(url)
tables <- html_table(url_parsed, fill = TRUE)
names(tables)
mps <- tables[[4]]
head(mps)
# clean up
head(mps)
names(mps) <- c("con", "name", "party")
mps <- mps[str_detect(mps$con, "\\[edit"),]
url_parsed <- read_html(url)
tables <- html_table(url_parsed, fill = TRUE)
names(tables)
mps <- tables[[4]]
head(mps)
# clean up
head(mps)
names(mps) <- c("con", "name", "party")
mps <- mps[!str_detect(mps$con, "\\[edit"),]
head(mps)
mps <- mps[-1,]
nrow(mps)
# look for Sirs
mps$name <- as.character(mps$name)
mps$sir <- str_detect(mps$name, "^Sir ")
table(mps$party, mps$sir)
prop.table(table(mps$party, mps$sir), 1)
812.76*0.94195
(7.50+63.35)*0.94195
(7.50+63.35)*0.91466
765.58+580.07+64.8
system("launchctl load ~/Library/LaunchAgents/spiegelheadlines.plist")
system("launchctl start spiegelheadlines")
system("launchctl list")
system("launchctl stop spiegelheadlines")
system("launchctl list")
system("launchctl stop spiegelheadlines")
system("launchctl unload ~/Library/LaunchAgents/spiegelheadlines.plist")
system("launchctl list")
system("launchctl list")
system("launchctl load ~/Library/LaunchAgents/spiegelheadlines.plist")
system("launchctl load ~/Library/LaunchAgents/spiegelheadlines.plist")
system("launchctl stop spiegelheadlines")
system("launchctl unload ~/Library/LaunchAgents/spiegelheadlines.plist")
system("launchctl load ~/Library/LaunchAgents/spiegelheadlines.plist")
system("launchctl start spiegelheadlines")
system("launchctl list")
system("launchctl stop spiegelheadlines")
system("launchctl unload ~/Library/LaunchAgents/spiegelheadlines.plist")
system("launchctl load ~/Library/LaunchAgents/spiegelheadlines.plist")
system("launchctl start spiegelheadlines")
system("launchctl list")
system("launchctl list")
system("launchctl unload ~/Library/LaunchAgents/scraperspiegelonline.plist")
system("launchctl stop scraperspiegelonline")
system("launchctl unload ~/Library/LaunchAgents/scraper_spiegel_online.plist")
system("launchctl list")
library(stringr)
library(magrittr)
library(httr)
Sys.time()
datetime <- str_replace_all(Sys.time(), "[ :]", "-")
datetime
browseURL("https://developer.apple.com/library/content/documentation/MacOSX/Conceptual/BPSystemStartup/Chapters/ScheduledJobs.html")
browseURL("https://developer.apple.com/library/content/documentation/MacOSX/Conceptual/BPSystemStartup/Chapters/ScheduledJobs.html")
system("launchctl list")
system("launchctl stop spiegelheadlines")
system("launchctl unload ~/Library/LaunchAgents/spiegelheadlines.plist")
system("launchctl list")
system("launchctl load ~/Library/LaunchAgents/spiegelheadlines.plist")
system("launchctl start spiegelheadlines")
system("launchctl stop spiegelheadlines")
system("launchctl unload ~/Library/LaunchAgents/spiegelheadlines.plist")
source("00-course-setup.r")
source("packages.r")
source("packages.r")
source("functions.r")
starships <- get_all_starships()
library(rwars)
starships <- get_all_starships()
foo <- plyr::rbind.fill(starships$results)
starships$results
foo <- lapply(starships$results, as.data.frame)
starships$results
browseURL("https://github.com/ropensci/opendata")
devtools::install_github("hrbrmstr/ipapi")
library(ipapi)
ip_df <- geolocate(c(NA, "10.0.1.1", "", "72.33.67.89", "dds.ec", " ", "search.twitter.com"), .progress=FALSE)
ip_df
ip_df <- geolocate(c(NA, "", "10.0.1.1", "", "72.33.67.89", "spiegel.de", "search.twitter.com"), .progress=FALSE)
ip_df <- geolocate(c(NA, "", "10.0.1.1", "", "72.33.67.89", "spiegel.de", "search.twitter.com"), .progress=FALSE)
?geolocate
ip_df <- geolocate(c(NA, "", "10.0.1.1", "", "72.33.67.89", "www.spiegel.de", "search.twitter.com"), .progress=TRUE)
View(ip_df)
url <- "http://ip-api.com/xml/"
read_xml(url)
?trimws
ip_parsed <- read_xml(url)
xml_find_all(ip_parsed, "//query")
data.frame(ip_parsed)
xmlToDataFrame(ip_parsed)
library(XML)
xmlToDataFrame(ip_parsed)
as_list(ip_parsed)
ip_list <- as_list(ip_parsed)
ip_list
str(ip_list)
unlist(ip_list)
ip_list %>% unlist %>% as.data.frame(stringsAsFactors = FALSE)
ip_list %>% unlist %>% t %>% as.data.frame(stringsAsFactors = FALSE)
url <- "http://ip-api.com/json/"
ip_parsed <- fromJSON(url)
url <- "http://ip-api.com/json"
ip_parsed <- fromJSON(url)
?fromJSON
ip_parsed <- jsonlite::fromJSON(url)
ip_parsed
?fromJSON
ip_parsed <- jsonlite::fromJSON(url, flatten = TRUE)
ip_parsed
ip_parsed <- jsonlite::fromJSON(url, simplifyDataFrame = TRUE, flatten = TRUE)
ip_parsed
ip_parsed <- jsonlite::fromJSON(url)
ip_parsed
ip_parsed %>% unlist %>% t %>% as.data.frame(stringsAsFactors = FALSE)
install.packages("translate")
install.packages("gdap")
install.packages("diezeit")
library(diezeit)
api_key <- "f9bd321bca869ff43311a8e83706413b82a099da993a41560640"
?zeit_search
foo <- zeit_search(endpoint="content", query="bayreuth")
str(foo)
length(foo)
author <- zeit_search(endpoint="author", query="stefan*locke")
author <- zeit_search(endpoint="author", query="johanna*haag")
author <- zeit_search(endpoint="author", query="tobias*landwehr")
author <- zeit_search(endpoint="keyword", query="wiedervereinigung")
author <- zeit_search(endpoint="series", query="deutschlandkarte")
series <- zeit_search(endpoint="series", query="deutschlandkarte")
zeit_get("content", "3Ed7KYJOO2MXu5SQtnudQA")
meta <- zeit_get("content", "3Ed7KYJOO2MXu5SQtnudQA")
merkel <- zeit_search(endpoint="content", query="title:Merkel")
str(merkel)
unlist(merkel)
foo <- zeit_search(endpoint="content", query="bayreuth")
names(foo)
dat <- zeit_search(endpoint="content", query="bayreuth")
names(dat)
dat$matches
dat$matches %>% unlist
str(dat$matches)
dd  <-  as.data.frame(matrix(unlist(dat$matches), nrow=length(dat$matches(listHolder[1]))))
length(dat$matches(listHolder[1])
dd  <-  as.data.frame(matrix(unlist(dat$matches), nrow=length(dat$matches(length(dat$matches(listHolder[1])[1]))))
foo <- zeit_search(endpoint="series", query="bayreuth")
author <- zeit_search(endpoint="author", query="tobias*landwehr")
dd  <-  as.data.frame(matrix(unlist(dat$matches), nrow=length(dat$matches(length(dat$matches(listHolder[1])[1])))))
dd  <-  as.data.frame(matrix(unlist(dat$matches),
nrow=length(unlist(dat$matches[1]))))
View(dd)
do.call(rbind, dat$matches).
do.call(rbind, dat$matches)
dd <- do.call(rbind, dat$matches)
View(dat$matches)
View(dd)
View(dd)
dd$snippelt
dd$snippet
names(dd)
class(dd)
dd <- do.call(rbind, dat$matches) %>% as.data.frame(stringsAsFactors = FALSE)
View(dd)
dd$snippet
sapply(dd, class)
df= as.data.frame(t(as.data.frame(dat$matches)))
View()
View(df)
as.data.frame(dat$matches)
do.call(c, unlist(dat$matches, recursive=FALSE))
sapply(dd, as.vector)
dd <- do.call(rbind, dat$matches) %>% as.data.frame(stringsAsFactors = FALSE)
View(dd)
sapply(dd, class)
sapply(dd, unlist)
ddd <- sapply(dd, unlist)
class(ddd)
ddd <- sapply(dd, unlist) %>% as.data.frame(stringsAsFactors = FALSE)
sapply(ddd, class)
View(ddd)
dd <- do.call(rbind, dat$matches) %>% as.data.frame(stringsAsFactors = FALSE) %>% sapply(unlist) %>% as.data.frame(stringsAsFactors = FALSE)
View(dd)
dd$snippet
foo <- zeit_search(endpoint="content", query="merkel")
merkel$found
merkel <- zeit_search(endpoint="content", query='"Kennedy" AND release_date:[1960-01-01T00:00:00Z TO 1969-12-31T23:59:59.999Z]')
meta <- zeit_get("content", "3Ed7KYJOO2MXu5SQtnudQA")
meta <- zeit_get("content", "Genug Liebe für mehr als zwei")
meta <- zeit_get("content", query = "Und Recht und Freibier", fields = "title")
meta <- zeit_get("content", "Und Recht und Freibier", fields = "title")
zeit_get
meta <- zeit_get("content", id = "Und Recht und Freibier", fields = "title")
zeit_client(print = TRUE)
?zeit_get
?zeit_search
?zeit_get
meta <- zeit_get("content", "3Ed7KYJOO2MXu5SQtnudQA")
